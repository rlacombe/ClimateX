{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from together import Together\n",
    "from dotenv import load_dotenv # pip install python-dotenv\n",
    "from utils.experiments import *\n",
    "from utils.analysis import *\n",
    "load_dotenv()   # Set API KEY values from .env file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook with example of how to run an experiment with a together.ai model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisites: \n",
    "\n",
    "- Make a Together.ai account (https://www.together.ai/), get a Together api key, and put it in a .env file in the root directory of this repo. \n",
    "    - in your .env file: TOGETHER_API_KEY=\"your api key\"\n",
    "- Python requirements: \n",
    "    - pip install together python-dotenv pandas numpy scikit-learn \n",
    "- Run all the code before the \"Choose Model\" markdown cell\n",
    "\n",
    "Yoou're ready to run experiments! \n",
    "You can copy cells in the \"run Experiment and Analyze\" section, change the model variable to any model string listed on https://docs.together.ai/docs/inference-models, and get running! \n",
    "\n",
    "Note: the results_df variable gets rewritten, so the notebook will not be happy if you run cells out of order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/ipcc_statements_dataset_original_cleaned_context.csv\")\n",
    "test_set = dataset[dataset[\"split\"]==\"test\"].copy()\n",
    "train_set = dataset[dataset[\"split\"]==\"train\"].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Together(api_key=os.environ.get(\"TOGETHER_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_together_model(client, statement, prompt_fn, model): \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt_fn(statement)}\n",
    "            ],\n",
    "        temperature=0, \n",
    "        logprobs=1,\n",
    "        )\n",
    "    raw_output = response.choices[0].message.content\n",
    "    cleaned_output = extract_confidence(raw_output)\n",
    "    logprobs = response.choices[0].logprobs\n",
    "    return pd.Series([raw_output, cleaned_output, logprobs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the model. n_sc = number of times to run the experiment, for self-consistency.\n",
    "# The input dataset will be modified with additional columns containing the results of the experiment.\n",
    "def run_experiment(dataset, model, n_sc=5, prompt_fn=get_zero_shot_prompt):\n",
    "    for i in range(1, n_sc+1):\n",
    "        dataset[[f\"raw_output_{i}\", f\"model_confidence_classification_{i}\", f\"model_logprobs{i}\"]] = dataset[\"final_statement\"].apply(lambda x: query_together_model(client, x, prompt_fn, model))\n",
    "    return dataset\n",
    "                                                                                                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose model - Llama 3 8B Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiment and Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"meta-llama/Llama-3-8b-chat-hf\"\n",
    "results_df = test_set.copy()\n",
    "results_df = run_experiment(results_df, model, 5, get_zero_shot_prompt) \n",
    "results_df.to_csv(f\"results/cleaned_dataset/{model.replace(\"/\", \"-\")}_zero_shot_06052024.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>statement_idx</th>\n",
       "      <th>report</th>\n",
       "      <th>page_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>original_statement</th>\n",
       "      <th>final_statement</th>\n",
       "      <th>confidence</th>\n",
       "      <th>score</th>\n",
       "      <th>...</th>\n",
       "      <th>model_logprobs2</th>\n",
       "      <th>raw_output_3</th>\n",
       "      <th>model_confidence_classification_3</th>\n",
       "      <th>model_logprobs3</th>\n",
       "      <th>raw_output_4</th>\n",
       "      <th>model_confidence_classification_4</th>\n",
       "      <th>model_logprobs4</th>\n",
       "      <th>raw_output_5</th>\n",
       "      <th>model_confidence_classification_5</th>\n",
       "      <th>model_logprobs5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>AR6_WGI</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>Since 1750, increases in CO 2 (47%) and CH 4 (...</td>\n",
       "      <td>Since 1750, increases in CO2 (47%) and CH4 (15...</td>\n",
       "      <td>very high</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>tokens=['very', ' high', '&lt;|eot_id|&gt;'] token_l...</td>\n",
       "      <td>very high</td>\n",
       "      <td>very high</td>\n",
       "      <td>tokens=['very', ' high', '&lt;|eot_id|&gt;'] token_l...</td>\n",
       "      <td>very high</td>\n",
       "      <td>very high</td>\n",
       "      <td>tokens=['very', ' high', '&lt;|eot_id|&gt;'] token_l...</td>\n",
       "      <td>very high</td>\n",
       "      <td>very high</td>\n",
       "      <td>tokens=['very', ' high', '&lt;|eot_id|&gt;'] token_l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>AR6_WGI</td>\n",
       "      <td>37</td>\n",
       "      <td>16</td>\n",
       "      <td>Over the next 2000 years, global mean sea leve...</td>\n",
       "      <td>Over the next 2000 years, global mean sea leve...</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>tokens=['very', ' high', '&lt;|eot_id|&gt;'] token_l...</td>\n",
       "      <td>very high</td>\n",
       "      <td>very high</td>\n",
       "      <td>tokens=['very', ' high', '&lt;|eot_id|&gt;'] token_l...</td>\n",
       "      <td>very high</td>\n",
       "      <td>very high</td>\n",
       "      <td>tokens=['very', ' high', '&lt;|eot_id|&gt;'] token_l...</td>\n",
       "      <td>very high</td>\n",
       "      <td>very high</td>\n",
       "      <td>tokens=['very', ' high', '&lt;|eot_id|&gt;'] token_l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>AR6_WGI</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>By the end of the century, scenarios with very...</td>\n",
       "      <td>By the end of the century, scenarios with very...</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>tokens=['High', '&lt;|eot_id|&gt;'] token_logprobs=[...</td>\n",
       "      <td>High</td>\n",
       "      <td>high</td>\n",
       "      <td>tokens=['High', '&lt;|eot_id|&gt;'] token_logprobs=[...</td>\n",
       "      <td>High</td>\n",
       "      <td>high</td>\n",
       "      <td>tokens=['High', '&lt;|eot_id|&gt;'] token_logprobs=[...</td>\n",
       "      <td>High</td>\n",
       "      <td>high</td>\n",
       "      <td>tokens=['High', '&lt;|eot_id|&gt;'] token_logprobs=[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>AR6_WGI</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>Over the past millennium, and especially since...</td>\n",
       "      <td>Over the past millennium, and especially since...</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>tokens=['medium', '&lt;|eot_id|&gt;'] token_logprobs...</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>tokens=['medium', '&lt;|eot_id|&gt;'] token_logprobs...</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>tokens=['medium', '&lt;|eot_id|&gt;'] token_logprobs...</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>tokens=['medium', '&lt;|eot_id|&gt;'] token_logprobs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>86</td>\n",
       "      <td>AR6_WGI</td>\n",
       "      <td>63</td>\n",
       "      <td>8</td>\n",
       "      <td>This paleo context supports the assessment tha...</td>\n",
       "      <td>The paleo context supports the assessment that...</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>tokens=['very', ' high', '&lt;|eot_id|&gt;'] token_l...</td>\n",
       "      <td>very high</td>\n",
       "      <td>very high</td>\n",
       "      <td>tokens=['very', ' high', '&lt;|eot_id|&gt;'] token_l...</td>\n",
       "      <td>very high</td>\n",
       "      <td>very high</td>\n",
       "      <td>tokens=['very', ' high', '&lt;|eot_id|&gt;'] token_l...</td>\n",
       "      <td>very high</td>\n",
       "      <td>very high</td>\n",
       "      <td>tokens=['very', ' high', '&lt;|eot_id|&gt;'] token_l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0.1  Unnamed: 0  statement_idx   report  page_num  sent_num  \\\n",
       "3              3           0              3  AR6_WGI        24         2   \n",
       "42            42           1             42  AR6_WGI        37        16   \n",
       "77            77           2             77  AR6_WGI        47         7   \n",
       "81            81           3             81  AR6_WGI        62         2   \n",
       "86            86           4             86  AR6_WGI        63         8   \n",
       "\n",
       "                                   original_statement  \\\n",
       "3   Since 1750, increases in CO 2 (47%) and CH 4 (...   \n",
       "42  Over the next 2000 years, global mean sea leve...   \n",
       "77  By the end of the century, scenarios with very...   \n",
       "81  Over the past millennium, and especially since...   \n",
       "86  This paleo context supports the assessment tha...   \n",
       "\n",
       "                                      final_statement confidence  score  ...  \\\n",
       "3   Since 1750, increases in CO2 (47%) and CH4 (15...  very high      3  ...   \n",
       "42  Over the next 2000 years, global mean sea leve...        low      0  ...   \n",
       "77  By the end of the century, scenarios with very...       high      2  ...   \n",
       "81  Over the past millennium, and especially since...     medium      1  ...   \n",
       "86  The paleo context supports the assessment that...       high      2  ...   \n",
       "\n",
       "                                      model_logprobs2 raw_output_3  \\\n",
       "3   tokens=['very', ' high', '<|eot_id|>'] token_l...    very high   \n",
       "42  tokens=['very', ' high', '<|eot_id|>'] token_l...    very high   \n",
       "77  tokens=['High', '<|eot_id|>'] token_logprobs=[...         High   \n",
       "81  tokens=['medium', '<|eot_id|>'] token_logprobs...       medium   \n",
       "86  tokens=['very', ' high', '<|eot_id|>'] token_l...    very high   \n",
       "\n",
       "    model_confidence_classification_3  \\\n",
       "3                           very high   \n",
       "42                          very high   \n",
       "77                               high   \n",
       "81                             medium   \n",
       "86                          very high   \n",
       "\n",
       "                                      model_logprobs3 raw_output_4  \\\n",
       "3   tokens=['very', ' high', '<|eot_id|>'] token_l...    very high   \n",
       "42  tokens=['very', ' high', '<|eot_id|>'] token_l...    very high   \n",
       "77  tokens=['High', '<|eot_id|>'] token_logprobs=[...         High   \n",
       "81  tokens=['medium', '<|eot_id|>'] token_logprobs...       medium   \n",
       "86  tokens=['very', ' high', '<|eot_id|>'] token_l...    very high   \n",
       "\n",
       "   model_confidence_classification_4  \\\n",
       "3                          very high   \n",
       "42                         very high   \n",
       "77                              high   \n",
       "81                            medium   \n",
       "86                         very high   \n",
       "\n",
       "                                      model_logprobs4 raw_output_5  \\\n",
       "3   tokens=['very', ' high', '<|eot_id|>'] token_l...    very high   \n",
       "42  tokens=['very', ' high', '<|eot_id|>'] token_l...    very high   \n",
       "77  tokens=['High', '<|eot_id|>'] token_logprobs=[...         High   \n",
       "81  tokens=['medium', '<|eot_id|>'] token_logprobs...       medium   \n",
       "86  tokens=['very', ' high', '<|eot_id|>'] token_l...    very high   \n",
       "\n",
       "   model_confidence_classification_5  \\\n",
       "3                          very high   \n",
       "42                         very high   \n",
       "77                              high   \n",
       "81                            medium   \n",
       "86                         very high   \n",
       "\n",
       "                                      model_logprobs5  \n",
       "3   tokens=['very', ' high', '<|eot_id|>'] token_l...  \n",
       "42  tokens=['very', ' high', '<|eot_id|>'] token_l...  \n",
       "77  tokens=['High', '<|eot_id|>'] token_logprobs=[...  \n",
       "81  tokens=['medium', '<|eot_id|>'] token_logprobs...  \n",
       "86  tokens=['very', ' high', '<|eot_id|>'] token_l...  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(\"results/cleaned_dataset/meta-llama-Llama-3-8b-chat-hf_zero_shot_06052024.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification_col_names = [f\"model_confidence_classification_{i}\" for i in range(1, 6)]\n",
    "print_accuracy_slope_bias_metrics(results_df, model_classification_col_names, plot=False, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
